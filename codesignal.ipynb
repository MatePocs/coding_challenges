{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: map, lambda, list comprehension\n",
    "window query like lag\n",
    "sklearn how to call lin reg, log reg, k means clustering, check out syntax\n",
    "regularisation , example 2.3.12, wtf\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook: gather notes to prepare for the Code Signal Data Science Assessment. The requirements are from this file: https://codesignal.com/wp-content/uploads/2019/08/data-science-assessment-framework.pdf\n",
    "<br>\n",
    "\n",
    "The maximum allowed completion time for the test is 80 minutes. Each test has 5 implementation tasks and 12 multiple choice quiz questions; in total, there are 17 tasks. \n",
    "<br>\n",
    "\n",
    "__Tasks__:\n",
    "\n",
    "- Programming implementation, 20 minutes, see example 2.2.1.\n",
    "- Bug-fixing, 5 minutes, see example 2.2.2.\n",
    "- Query, 10 minutes, example 2.2.3.\n",
    "- 2 * Probability and statistics recovery, 10 minutes\n",
    "- 3 * Quiz with 4 questions, 8 minutes each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- primitive data types (ints/floats/strings)\n",
    "- basic arithmetic/logical operations, \n",
    "- loops and decision constructs, \n",
    "- basic collections (arrays, lists, and dictionaries/sets), \n",
    "- lambda functions, list comprehensions,\n",
    "- using libraries highly relevant to data science/analysis (e.g., python numpy/pandas/scikit-learn). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a list of strings (data) where each string is in the form `device_id`,`usage_in_minutes` such that `device_id` contains exactly five lowercase English alphabets (’a’-’z’) and `usage_in_minutes` is a positive integer between 1 and 1,440 with leading zeroes (if necessary, to make its length equal to 4). For instance, “abxyz,0010\" describes `device_id` = “abxyz” and `usage_in_minutes` = 10 minutes. Given data, return the `device_id` with the largest value of `usage_in_minutes`. You may assume that `device_id`’s are distinct and `usage_in_minutes` are distinct in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abxyz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_largest_device_id(list_of_strings):\n",
    "    max_usage = 0\n",
    "    max_device = ''\n",
    "    for item in list_of_strings:\n",
    "        current_device, current_usage = item.split(',')\n",
    "        current_usage = int(current_usage)\n",
    "        if current_usage > max_usage:\n",
    "            max_usage = current_usage\n",
    "            max_device = current_device\n",
    "            \n",
    "    return max_device\n",
    "        \n",
    "test_list = [\"abxyz,0016\", \"cdfgh,0015\"]\n",
    "return_largest_device_id(test_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a function that is given an array/list A of distinct integers and an integer k (where 1 ≤ k ≤ len(A)), and returns all possible subarrays of A by removing k contiguous elements in A. That is, you wish to obtain a subarray of A by removing the first k elements in A, another subarray of A by removing the next k elements in A, and so on.\n",
    "<br>\n",
    "\n",
    "For instance, when A = [2, 4, 6, 8, 10] and k = 3, you can remove \n",
    "- [2, 4, 6] (which results in [8, 10]), \n",
    "- [4, 6, 8](which results in [2, 10]), or \n",
    "- [6, 8, 10] (which results in [2, 4]).\n",
    "<br>\n",
    "\n",
    "Since you are removing k elements from A, you always obtain a subarray of length (len(A) − k), and there are (len(A) − k + 1) such subarrays. \n",
    "\n",
    "<br>\n",
    "In the provided code, the given function contains a buggy line of code. You are asked to find and \u001fx one\n",
    "line of code so that the function will return a list of subarrays correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 4, 6, 8, 4, 6, 8, 10], [6, 8, 10], [2, 8, 10]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_k_elems(A, k):\n",
    "    n = len(A)\n",
    "    result = lambda arr, idx: arr[0:(idx-1)] + arr[(idx+1):n]\n",
    "    return [ result(A, i) for i in range(n-k+1) ]\n",
    "\n",
    "A = [2, 4, 6, 8, 10] \n",
    "k = 3\n",
    "remove_k_elems(A,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lambda arr, idx: arr[0:idx] + arr[(idx+k+1):len(A)]\n",
    "\n",
    "result(A, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 10], [2, 10], [2, 4]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_k_elems_corrected(A, k):\n",
    "    n = len(A)\n",
    "    result = lambda arr, idx: arr[0:idx] + arr[(idx+k):n]\n",
    "    return [ result(A, i) for i in range(n-k+1) ]\n",
    "\n",
    "A = [2, 4, 6, 8, 10] \n",
    "k = 3\n",
    "remove_k_elems_corrected(A,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basics: Filtering, Sorting, Aggregate Functions,\n",
    "- If, Case and String Functions,\n",
    "- subqueries (innerqueries), \n",
    "- joins (inner, left, right),\n",
    "- window functions and window-specific aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples to check out: \n",
    "<br>\n",
    "\n",
    "- value functions:  FIRST_VALUE(), LAST_VALUE(), LAG()\n",
    "- aggregate functions: AVG(), COUNT(), MAX(), MIN(), AVG(), OVER()\n",
    "- ranking functions: RANK(), ROW_NUMBER(), DENSE_RANK, CUME_DIST()\n",
    "<br>\n",
    "\n",
    "Similar to aggregate functions, but without GROUP BY. \n",
    "<br>\n",
    "\n",
    "I think this is a good guide: \n",
    "https://learnsql.com/blog/sql-window-functions-examples/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK: returns position of any row within partition\n",
    "\n",
    "# rank employees by order of salary within each department. \n",
    "\n",
    "\"\"\"\n",
    "SELECT\n",
    "    RANK() OVER (PARTITION BY department ORDER BY salary DESC) \n",
    "    AS dept_ranking,\n",
    "    department,\n",
    "    employee_id, \n",
    "    full_name, \n",
    "    salary\n",
    "FROM employee;\n",
    "\"\"\"\n",
    "\n",
    "# create a salary metric that shows the current salary / highest salary in that department ratio\n",
    "\n",
    "\"\"\"\n",
    "SELECT  employee_id, \n",
    "    full_name, \n",
    "    department,\n",
    "    salary,\n",
    "    salary / MAX(salary) OVER (PARTITION BY department ORDER BY salary DESC) \n",
    "    AS salary_metric\n",
    "FROM employee\n",
    "ORDER BY 5;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query: \n",
    "\"\"\"\n",
    "SELECT\n",
    "    os,\n",
    "    country,\n",
    "    COUNT(user_id) AS num_user\n",
    "FROM\n",
    "    Input_table # quiz example 2.1\n",
    "WHERE\n",
    "    country != 'USA'\n",
    "    GROUP BY 1, 2\n",
    "    ORDER BY 3 DESC, 1, 2\n",
    "    LIMIT 2\n",
    "\"\"\"\n",
    "# table:\n",
    "\"\"\"\n",
    "user_id os country\n",
    "user1 iOS USA\n",
    "user4 iOS GBR\n",
    "user3 iOS CAN\n",
    "user5 iOS FRA\n",
    "user2 iOS USA\n",
    "user6 iOS GBR\n",
    "user8 Android GBR\n",
    "user7 Android USA\n",
    "user9 Android FRA\n",
    "user10 Android FRA\n",
    "\"\"\"\n",
    "# solution: \n",
    "\"\"\"\n",
    "os country num_user\n",
    "Android FRA 2\n",
    "iOS GBR 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Variables, Events, Probability Distributions, conditional probability, Bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today you have 4 lectures to attend. In each lecture, there is a 10% probability that you will be given a popup quiz (and whether you will be given a pop-up quiz in one lecture or not is independent of another lecture).\n",
    "\n",
    "What is the probability that you will be given at least one pop-up quiz today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3439"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_not_having = 0.9 ** 4\n",
    "prob_of_having = 1 - prob_of_not_having \n",
    "prob_of_having"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two factories produce identical products. Factory A produces 1,000 products per hour, and on average 980 products (out of 1,000) meet the safety requirements. Factory B produces 2,000 products per hour, and on average 1950 products (out of 2,000) meet the safety requirements. \n",
    "\n",
    "Given an arbitrary product that did not meet the safety requirements, compute the probability that it was produced by factory A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a very simple solution in the pdf, without bayes: \n",
    "# every hour, there are 7 wrong ones, and 2 of them are from A... so 2/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023333333333333338"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_bad_assuming_A = 20/1000\n",
    "prob_bad_assuming_B = 50/2000\n",
    "prob_A = 1000 / 3000\n",
    "prob_bad = (prob_A * prob_bad_assuming_A) + ((1 - prob_A) * prob_bad_assuming_B)\n",
    "\n",
    "prob_bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28571428571428564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_A_assuming_bad = prob_bad_assuming_A * prob_A / prob_bad\n",
    "\n",
    "prob_A_assuming_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean/Median/Mode, Standard Deviation, z-score,\n",
    "p-value, t-statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html\n",
    "<br>\n",
    "\n",
    "Has two array inputs, nullhyp is that the average of two population is the same. \n",
    "\n",
    "Returns a tuple of t-statistic and p-value\n",
    "\n",
    "If p-value is smaller than alpha: reject nullhyp\n",
    "\n",
    "Large t-value means reject\n",
    "\n",
    "http://www.insightsbot.com/python-t-test-a-friendly-guide/\n",
    "three different t-tests: \n",
    "- independent: two unrelated populations: ttest_ind\n",
    "- paired sample: before-after type of deals: ttest_rel\n",
    "- one-sample: is the average different from a number: ttest_1samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task focuses on two-tailed, paired t-test and data cleaning.\n",
    "<br>\n",
    "\n",
    "You are analyzing the effectiveness of a tutorial used in your statistics class. You asked n students to take a standardized test before starting the tutorial and to take another test after completing the tutorial. A valid score from this test ranges from 300 to 500, inclusive. However, due to some bug in the grading system, some of the test were (incorrectly) graded such that scores of those tests were increased by a factor of two (i.e., they range from 600 to 1,000). \n",
    "<br>\n",
    "\n",
    "After correcting this error, you want to perform a t-test with the following hypotheses:\n",
    "- H0 (null): The average difference between before-tutorial and after-tutorial is 0.\n",
    "- H1 (alternative): The average difference is non-zero.\n",
    "<br>\n",
    "\n",
    "Complete the following code so that `should_reject()` returns true if the null hypothesis is rejected at the significance specified by alpha, and false otherwise.\n",
    "\n",
    "Assume that the conditions of your t-test are met (after fixing the incorrect scores).\n",
    "\n",
    "Constraints: score_before and score_after will contain the same number of elements (between 10 and 50 elements each, inclusive). Each element in `score_before` and `score_after` will be an integer between 300 and\n",
    "1,000, inclusive. `alpha` will be between 0.001 and 0.10, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score adjustment part is easy, you just divide by two if larger than 500\n",
    "# after that, it's a standard t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def should_reject(score_before, score_after, alpha):\n",
    "    correction = lambda x: x if x <= 500 else x/2.0\n",
    "    s1, s2 = map(correction, score_before),map(correction, score_after)\n",
    "    \n",
    "    return stats.ttest_rel(s1, s2).pvalue < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, touche. So the sum of deviations from the mean is 0 for any list, that is what mean is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "120 students took the final exam of Data Science 101, and the statistics of the scores are as follows:\n",
    "- Min = 20, Mean = 75, Max = 105\n",
    "- Standard deviation = 20\n",
    "\n",
    "One of the student’s z-score (standard score) is 1.30. What’s the student’s exam score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-score is (original - mean) / stdev, so \n",
    "z_score = 1.3\n",
    "mean = 75\n",
    "stdev = 20\n",
    "original_score = z_score * stdev + mean\n",
    "original_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a real-value independent variable A and realvalue dependent variable B. You wish to model the relationship between A and B using linear regression, and compute the mean squared error of the said model using leave-one-out validation method. Write a function that returns the mean squared error of linear regression model, given n observed values of A and B as obs_A and obs_B. Assume that both obs_A and obs_B contain exactly n elements each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_loo(n, obs_A, obs_B):\n",
    "    error_sum = 0.\n",
    "    loo = lambda arr, idx: arr[:idx] + arr[(idx+1):]\n",
    "    \n",
    "    for i in range(n):\n",
    "        A_train = loo(obs_A, i)\n",
    "        B_train = loo(obs_B, i)\n",
    "        mean_A = sum(A_train) / (n-1.0)\n",
    "        mean_B = sum(B_train) / (n-1.0)\n",
    "        \n",
    "        slope = sum(map(lambda ab: (ab[0] - mean_A)*(ab[1] - mean_B), zip(A_train, B_train))) \\\n",
    "        / float(sum(map(lambda a: (a-mean_A)**2,A_train)))\n",
    "        \n",
    "        intercept = mean_B - slope * mean_A\n",
    "    \n",
    "        pred_B = slope * obs_A[i] + intercept\n",
    "        error_sum += (pred_B - obs_B[i])**2\n",
    "\n",
    "    return error_sum / float(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically the part that needed to be entered is the slope. Which is not how I would calculate it, I think this is impressive but not readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-out cross-validation: what you would expect, always ignores one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following data with one real-value independent variable (X) and one real-value dependent variable (Y ), which you wish to model using linear regression (Y = a · X + b). \n",
    "\n",
    "X: [0, 2, 3]\n",
    "\n",
    "Y: [1, 2, 1]\n",
    "\n",
    "If you use leave-one-out cross validation, what would be the mean square error of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the dots, for two points, we can of course just draw the lines, so it's easy to calculate the mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.083333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we leave out index 0, 1, and 2, the correspoinding errors are: \n",
    "sq_err_0 = 9\n",
    "sq_err_1 = 1\n",
    "sq_err_2 = 1.5 ** 2\n",
    "\n",
    "mean_sq_err = (sq_err_0 + sq_err_1 + sq_err_2) / 3\n",
    "mean_sq_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.083333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an example with the sigmoid function, but I think it's simple enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization in Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3.12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a linear regression model where we estimate\n",
    "the regression coefficients (β) by minimizing\n",
    "Xn\n",
    "i=1\n",
    "(yi − β0 −\n",
    "Xp\n",
    "j=1\n",
    "βj · xij )\n",
    "2 + λ\n",
    "Xp\n",
    "j=1\n",
    "β\n",
    "2\n",
    "j\n",
    "subject to Pp\n",
    "j=1 |βj | ≤ µ for a particular value of λ and\n",
    "µ. Note that n is the number of (training) examples and\n",
    "p is the number of features.\n",
    "\n",
    "So with lambda is the standar l2-regularised formula. https://en.wikipedia.org/wiki/Tikhonov_regularization, with mu, this is l1. \n",
    "\n",
    "True statements:\n",
    "\n",
    "- As we increase λ from 0 while keeping µ = +∞, the training residual sum of squares (RSS) will steadily increase (up to a certain limit).\n",
    "- As we increase λ from 0 while keeping µ = +∞, the model’s variance will steadily decrease (down to a certain limit).\n",
    "- As we increase µ from 0 while keeping λ = 0, the model’s squared bias steadily decrease (down to a certain limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
